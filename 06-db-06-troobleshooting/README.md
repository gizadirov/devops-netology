# Домашнее задание к занятию 6. «Troubleshooting»## Задача 1Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD-операция в MongoDB и её нужно прервать. Вы как инженер поддержки решили произвести эту операцию:- напишите список операций, которые вы будете производить для остановки запроса пользователя;- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB.## ОтветЧтобы остановить запросы пользователя, сначала нам нужно узнать их идентификаторы (oid):  ```# список операций, длительностью больше 3 минутdb.currentOp(   {     "active" : true,     "secs_running" : { "$gt" : 180 },   })```Потом можно убить операцию по наденному oid:```commandlinedb.killOp(<oid>)```Для решения проблемы с зависающими запросами можно предложить включить мониторинг и отлавливать долгие запросы, а потом их оптимизировать с помощью команды ``explain``, которая позволяет посмотреть план выполнения запроса. Можно также увеличить максимальное время запроса установкой `$maxTimeMS`## Задача 2Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. Причём отношение количества записанных key-value-значений к количеству истёкших значений есть величина постоянная иувеличивается пропорционально количеству реплик сервиса. При масштабировании сервиса до N реплик вы увидели, что:- сначала происходит рост отношения записанных значений к истекшим,- Redis блокирует операции записи.Как вы думаете, в чём может быть проблема?## ОтветЯ думаю, что проблема возникает из-за алгоритма удаления ключей с TTL.  Redis 10 раз в секунду проделывает следующее:1. Тестирует `ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP` = 20 случайных ключей из всего набора ключей в БД с проставленным TTL.2. Удаляет все ключи с просроченным сроком жизни.3. Если более 25% ключей удалены, возвращаемся к пункту 1.Redis блокирует операции записи, потому что занят удалением ключей с одинаковым временем истечения (их количество, видимо, увеличилось с масштабированием сервиса), входя в долгий цикл 1 - 3## Задача 3Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей в таблицах базыпользователи начали жаловаться на ошибки вида:```pythonInterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '```Как вы думаете, почему это начало происходить и как локализовать проблему?Какие пути решения этой проблемы вы можете предложить?## ОтветВероятные причины:1) Сетевые проблемы. Необходимо проверить подключение.2) Посмотреть, может быть недостаточный `connection_timeout`. Если ``SHOW GLOBAL STATUS LIKE 'Aborted_connects'`` увеличивается, значит сервер сам прекращает соединение и надо увеличить timeout. 2) Слишком долгий запрос, который не успевает отработать за `net_read_timeout` = 30с. Увеличить данный параметр или оптимизировать запрос, создать индексы.3) Превышение размера сообщения. Необходимо увеличить параметр `max_allowed_packet` или оптимизировать запрос.## Задача 4Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с большим объёмом данных лучше, чем MySQL.После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:`postmaster invoked oom-killer`Как вы думаете, что происходит?Как бы вы решили эту проблему?## ОтветOut-Of-Memory Killer — это процесс, который запускается при исчерпании памяти (out of memory) и завершает приложение, чтобы спасти ядро от сбоя. Он жертвует приложением, чтобы сохранить работу ОС.  Поэтому понятно, что PostreSQL утилизировал всю доступную ему оперативную память.1) Для решения проблемы с памятью в PostgreSQL я бы воспользовался специально утилитой ``pg_top``, которая показывает сколько памяти отводится на каждый запрос. Также посмотрел бы логи.2) Провел бы оптимизацию запросов и проверил использование индексов.3) Посмотрел бы параметры, касающиеся памяти: shared_buffers, work_mem, max_connections, temp_buffers, maintenance_work_mem, autovacuum_work_mem, wal_buffers и как их можно оптимизировать.4) Рассмотрел бы возможность использования connection pooler.5) Можно просто увеличить память, если ничего умнее не нашлось.